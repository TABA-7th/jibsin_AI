import time
import pandas as pd
import cv2
import json
from PIL import Image
import requests
import uuid
import time
import openai
import re
import base64
import numpy as np
import os
from io import BytesIO
from dotenv import load_dotenv
from firebase_api.utils import save_ocr_result_to_firestore

load_dotenv()

# API ì„¤ì •
secret_key = os.getenv("OCR_SECRET_KEY")
api_url = os.getenv("OCR_API_URL")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MODEL = "gpt-4o" # ì¼ë‹¨ í´ë¡œë“œê°€ ë²„ì „ ë°”ê¾¸ë¼í•´ì„œ ë°”ê¾¸ëŠ”ë° ë‚˜ì¤‘ì— ë¬¸ì œìƒê¸°ë©´ 4-oë¡œ

client = openai.OpenAI(api_key=OPENAI_API_KEY)
#ê³„ì•½ì„œì›ë³¸ì–‘ì‹
def registry_xy_mapping():
    rows = [
        ['ë“±ê¸°ì‚¬í•­ì „ë¶€ì¦ëª…ì„œ',348,112,934,162],
        ['ì§‘í•©ê±´ë¬¼',520,166,766,216],
        ['[ì§‘í•©ê±´ë¬¼] ê±´ë¬¼ì£¼ì†Œ',26,298,908,346],
        ['[í‘œì œë¶€](1ë™ì˜ ê±´ë¬¼ì˜ í‘œì‹œ)',94,354,632,392],
        ['í‘œì‹œë²ˆí˜¸',34,406,130,444],
        ['ì ‘ìˆ˜',172,414,268,440],
        ['ì†Œì¬ì§€ë²ˆ, ê±´ë¬¼ ëª…ì¹­ ë° ë²ˆí˜¸', 318,410,590,440],
        ['([ë„ë¡œëª…ì£¼ì†Œ])',312,456,580,642],
        ['ê±´ë¬¼ë‚´ì—­',668,410,808,446],
        ['ë“±ê¸° ì›ì¸ ë° ê¸°íƒ€ì‚¬í•­',904,404,1140,448],
        ['ì—´ëŒì¼ì‹œ',22,1620,456,1656],
        ['(ëŒ€ì§€ê¶Œì´ ëª©ì ì¸ í† ì§€ì˜ í‘œì‹œ)',408,2456,788,2496],
        ['[í‘œì œë¶€] (ì „ìœ ë¶€ë¶„ì˜ ê±´ë¬¼ì˜ í‘œì‹œ)',80,2672,684,2720],
        ['í‘œì‹œë²ˆí˜¸',40,2740,130,2776],
        ['ì ‘ìˆ˜',166,2732,280,2776],
        ['ê±´ë¬¼ë²ˆí˜¸',322,2732,480,2780],
        ['(ê±´ë¬¼ë²ˆí˜¸)',316,2784,490,2842],
        ['ê±´ë¬¼ë‚´ì—­',522,2742,694,2770],
        ['(ê±´ë¬¼ë‚´ì—­)',506,2790,706,2850],
        ['ë“±ê¸°ì›ì¸ ë° ê¸°íƒ€ì‚¬í•­',806,2736,1064,2772],
        ['[ê°‘ êµ¬] (ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)',86,3842,654,3898],
        ['ìˆœìœ„ë²ˆí˜¸',46,3908,134,3948],
        ['ë“±ê¸°ëª©ì ',170,3910,314,3944],
        ['ì ‘ìˆ˜', 390,3904,490,3946],
        ['ë“±ê¸°ì›ì¸',524,3906,668,3952],
        ['ê´€ë¦¬ì ë° ê¸°íƒ€ì‚¬í•­',824,3902,1030,3946],
        ['(ê°‘êµ¬)',38,3902,1156,4526],
        ['[ì„ êµ¬] (ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ëŒ€í•œ ì‚¬í•­)', 88,4562,796,4608],
        ['ìˆœìœ„ë²ˆí˜¸',46,4628,134,4658],
        ['ë“±ê¸°ëª©ì ',170,4628,314,4658],
        ['ì ‘ìˆ˜', 390,4628,490,4658],
        ['ë“±ê¸°ì›ì¸',524,4628,668,4658],
        ['ê´€ë¦¬ì ë° ê¸°íƒ€ì‚¬í•­',824,4628,1030,4658],
        ['(ì±„ê¶Œìµœê³ ì•¡)',718,4662,1156,4752]
    ]
    xy = pd.DataFrame(columns=['Text', 'x1', 'y1', 'x2', 'y2'])
    xy = pd.concat([xy, pd.DataFrame(rows, columns=xy.columns)], ignore_index=True)
    return xy

def merge_images(image_urls):
    """Firebase URLë¡œë¶€í„° ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ë³‘í•©"""
    target_size = (1240, 1755)  # ì›í•˜ëŠ” ì´ë¯¸ì§€ í¬ê¸°

    # ì´ë¯¸ì§€ ë¶ˆëŸ¬ì™€ í¬ê¸° ì¡°ì •
    images = []
    for url in image_urls:
        # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        response = requests.get(url)
        if response.status_code == 200:
            # ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            image = Image.open(BytesIO(response.content))
            # PIL Imageë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            # í¬ê¸° ì¡°ì •
            resized_image = cv2.resize(opencv_image, target_size, interpolation=cv2.INTER_AREA)
            # ë‹¤ì‹œ PIL Imageë¡œ ë³€í™˜
            images.append(Image.fromarray(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)))
    
    # ì´ë¯¸ì§€ ë³‘í•©
    total_height = sum(img.height for img in images)
    max_width = max(img.width for img in images)
    merged_image = Image.new("RGB", (max_width, total_height))

    # ì´ë¯¸ì§€ ë¶™ì´ê¸°
    y_offset = 0
    for img in images:
        merged_image.paste(img, (0, y_offset))
        y_offset += img.height
    
    # ë³‘í•©ëœ ì´ë¯¸ì§€ ì €ì¥
    merged_image.save("merged_registry_image.jpg")
    
    return merged_image

def cre_ocr(image):
    """PIL Image ê°ì²´ì— ëŒ€í•´ OCR ì‹¤í–‰"""
    request_json = {
        'images': [
            {
                'format': 'jpg',
                'name': 'demo'
            }
        ],
        'requestId': str(uuid.uuid4()),
        'version': 'V2',
        'timestamp': int(round(time.time() * 1000))
    }
    
    # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ ë²„í¼ë¡œ ë³€í™˜
    buffer = BytesIO()
    image.save(buffer, format="JPEG")
    image_bytes = buffer.getvalue()
    
    payload = {'message': json.dumps(request_json).encode('UTF-8')}
    files = [('file', ('image.jpg', image_bytes, 'image/jpeg'))]
    headers = {'X-OCR-SECRET': secret_key}
    
    response = requests.post(api_url, headers=headers, data=payload, files=files)
    
    if response.status_code == 200:
        ocr_results = response.json()

        all_data = []
        for image_result in ocr_results['images']:
            for field in image_result['fields']:
                text = field['inferText']
                bounding_box = field['boundingPoly']['vertices']
                x1, y1 = int(bounding_box[0]['x']), int(bounding_box[0]['y'])
                x2, y2 = int(bounding_box[2]['x']), int(bounding_box[2]['y'])
                all_data.append({
                    "Text": text,
                    "x1": x1, "y1": y1,
                    "x2": x2, "y2": y2
                })
        df = pd.DataFrame(all_data)
        return df
    return None

def fix_json_format(text: str) -> str:
    """JSON í˜•ì‹ ì˜¤ë¥˜ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì •í•˜ëŠ” í•¨ìˆ˜"""
    text = text.strip()
    text = text.replace("```json", "").replace("```", "").strip()
    
    json_end_index = text.rfind("}")
    if json_end_index != -1:
        text = text[:json_end_index+1]
    
    text = re.sub(r'}\s*{', '}, {', text)
    text = re.sub(r'(\d{1,3})(\d{3},\d{3})', r'\1,\2', text)
    
    return text

def format_registry_json(text: str, output_file: str) -> str:
    """OCR ê²°ê³¼ JSON ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ê³  ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    try:
        text = fix_json_format(text)
        data = json.loads(text)

        def fix_text(value):
            if value == "NA":
                return value
            value = re.sub(r'(\d+)\s+(\d+)', r'\1,\2', value)
            return value.strip()

        for key, value in data.items():
            if isinstance(value, dict) and "text" in value:
                value["text"] = fix_text(value["text"])

        y1_value = data.get("(ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)", {}).get("bounding_box", {}).get("y2", 0)
        y2_value = data.get("(ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ê´€í•œ ì‚¬í•­)", {}).get("bounding_box", {}).get("y1", 0)

        data["ê°‘êµ¬"] = {
            "text": "(ê°‘êµ¬)",
            "bounding_box": {
                "x1": 0,
                "y1": y1_value,
                "x2": 1200,
                "y2": y2_value
            }
        }

        # "(ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)"ê³¼ "(ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ê´€í•œ ì‚¬í•­)"ì„ ì‚­ì œ
        data.pop("(ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)", None)
        data.pop("(ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ê´€í•œ ì‚¬í•­)", None)

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=4)

        print(f"âœ… ë“±ê¸°ë¶€ë“±ë³¸ JSON ì •ë¦¬ ì™„ë£Œ: {output_file}")
        return output_file

    except json.JSONDecodeError as e:
        print(f"âŒ JSON ë³€í™˜ ì‹¤íŒ¨: {e}")
        print("ğŸ“Œ ì˜¤ë¥˜ ë°œìƒ JSON ë‚´ìš©:\n", text)
        return f"âŒ JSON ë³€í™˜ ì‹¤íŒ¨: {e}"

def registry_keyword_ocr(image_urls, doc_type):
    """ë©”ì¸ OCR ì²˜ë¦¬ í•¨ìˆ˜"""
    # ì´ë¯¸ì§€ ë³‘í•©
    merged_image = merge_images(image_urls)
    
    
    # OCR ìˆ˜í–‰
    df = cre_ocr(merged_image)
    
    if df is None:
        print("OCR ì²˜ë¦¬ ì‹¤íŒ¨")
        return None

    all_results = {}
    page_height = 1755
    
    for idx, image_url in enumerate(image_urls):
        # URLì—ì„œ group_idì™€ page_number ì¶”ì¶œ
        group_id = re.search(r'scanned_documents%2F(.*?)%2F', image_url).group(1)
        page_number = re.search(r'page(\d+)', image_url).group(1)

        # í˜„ì¬ í˜ì´ì§€ì˜ y ì¢Œí‘œ ë²”ìœ„ ê³„ì‚°
        y_start = idx * page_height
        y_end = (idx + 1) * page_height

        # í˜„ì¬ í˜ì´ì§€ì— í•´ë‹¹í•˜ëŠ” OCR ê²°ê³¼ë§Œ í•„í„°ë§
        page_df = df[
            (df['y1'] >= y_start) & 
            (df['y1'] < y_end)
        ].copy()

        # y ì¢Œí‘œ ì¡°ì • (í˜ì´ì§€ ë‚´ ìƒëŒ€ ì¢Œí‘œë¡œ ë³€í™˜)
        page_df['y1'] = page_df['y1'] - y_start
        page_df['y2'] = page_df['y2'] - y_start

        xy = registry_xy_mapping()
        xy_json = xy.to_json(orient="records", force_ascii=False)
        page_df_json = page_df.to_json(orient="records", force_ascii=False)

        target_texts = {
            "ì¢…ë¥˜": "ë“±ë³¸ ì¢…ë¥˜ (ì§‘í•©ê±´ë¬¼, ê±´ë¬¼, í† ì§€ ì¤‘ í•˜ë‚˜)",
            "(ê±´ë¬¼ì£¼ì†Œ)": "[ë“±ë³¸ì¢…ë¥˜] ë„ë¡œëª… ì£¼ì†Œ (ì˜ˆ: [ì§‘í•©ê±´ë¬¼] ì •ì™•ëŒ€ë¡œ 53ë²ˆê¸¸ 29)",
            "(ê°‘êµ¬)":"í…ìŠ¤íŠ¸",
            "(ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)": "(ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)",
            "(ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ëŒ€í•œ ì‚¬í•­)":"(ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ëŒ€í•œ ì‚¬í•­)",
            "(ì±„ê¶Œìµœê³ ì•¡)": "ìµœê³ ì±„ê¶Œì•¡ ê¸ˆ ###ì›(ì˜ˆ: ì±„ê¶Œìµœê³ ì•¡ ê¸ˆ1,000,000,000ì›)"
        }
    
    
    # GPT ë¶„ì„ ìš”ì²­
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    "role": "system",
                    "content": "JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ë§ˆí¬ë‹¤ìš´ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": [
                        {
                        "type": "text",
                        "text": (
                            f"ë‹¤ìŒì€ OCR ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ì…ë‹ˆë‹¤.\n\n"
                            f"**ìœ„ì¹˜ ë°ì´í„° (xy):**\n{xy_json}\n\n"
                            f"**ë‚´ìš© ë°ì´í„° (df):**\n{page_df_json}\n\n"
                            f"**ì‘ì—… ëª©í‘œ:**\n"
                            f"- ë‚´ìš©ì´ ì—†ìœ¼ë©´ 'NA'ë¡œ í‘œì‹œ\n\n"
                            f"- `xy` ë°ì´í„°ì˜ ìœ„ì¹˜ ì •ë³´(ì¢Œí‘œ)ë¥¼ í™œìš©í•˜ì—¬ `df` ë°ì´í„°ì™€ ë§¤ì¹­. {xy_json}ì˜ ìœ„ì¹˜ëŠ” ì°¸ê³ ë§Œí•˜ê³  í•­ìƒ {page_df_json}ì„ ë”°ë¥¸ë‹¤.\n"
                            f"- 'xy' ë°ì´í„°ì˜ ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸°ëŠ” 'df'ì— ë§ê²Œ ì¡°ì •ëœë‹¤"
                            f"ğŸ”¹ **ê° í•­ëª©ì˜ ì¶œë ¥ í˜•ì‹:**\n"
                            + "\n".join([f"- **{key}**: {value}" for key, value in target_texts.items()]) +
                            f"\n\n**ê²°ê³¼ í˜•ì‹:**\n"
                            f"- JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ (ê° í•­ëª©ì˜ ë°”ìš´ë”© ë°•ìŠ¤ í¬í•¨)\n"
                            f"- **ì¶œë ¥ ë°ì´í„°ê°€ ì§€ì •ëœ í˜•ì‹ê³¼ ë‹¤ë¥¼ ê²½ìš° ìë™ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜**\n\n"
                            f"**ë°˜í™˜ ì˜ˆì‹œ:**\n"
                            f"{{\n"
                            f"  \"ì¢…ë¥˜\": {{\"text\": \"ì§‘í•©ê±´ë¬¼\", \"bounding_box\": {{\"x1\": 100, \"y1\": 200, \"x2\": 300, \"y2\": 250}}}},\n"
                            f"  \"ê±´ë¬¼ì£¼ì†Œ\": {{\"text\": \"ì •ì™•ëŒ€ë¡œ 53ë²ˆê¸¸ 29\", \"bounding_box\": {{\"x1\": 120, \"y1\": 220, \"x2\": 320, \"y2\": 270}}}},\n"
                            f"  \"(ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)\": {{\"text\": \"( ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­ )\", \"bounding_box\": {{\"x1\": 120, \"y1\": 220, \"x2\": 320, \"y2\": 270}}}},\n"
                            f"  \"(ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ê´€í•œ ì‚¬í•­)\": {{\"text\": \"( ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ê´€í•œ ì‚¬í•­ )\", \"bounding_box\": {{\"x1\": 120, \"y1\": 220, \"x2\": 320, \"y2\": 270}}}},\n"                            
                            f"  \"ì—´ëŒì¼ì‹œ\": {{\"text\": \"2025ë…„ 02ì›” 15ì¼ 14ì‹œ 48ë¶„\", \"bounding_box\": {{\"x1\": 150, \"y1\": 250, \"x2\": 350, \"y2\": 300}}}},\n"
                            f"  \"ì±„ê¶Œìµœê³ ì•¡\": {{\"text\": \"ì±„ê¶Œìµœê³ ì•¡ ê¸ˆ1,000,000,000ì›\", \"bounding_box\": {{\"x1\": 170, \"y1\": 270, \"x2\": 370, \"y2\": 320}}}}\n"
                            f"}}\n\n"
                            f"**ì£¼ì˜ì‚¬í•­:**\n"
                            f"- ë‚´ìš©ì´ ì—†ì„ ê²½ìš° `NA`ë¡œ ë°˜í™˜, text ë‚´ìš©ì´ ì—†ëŠ” ê²½ìš° ì¢Œí‘œë¥¼ 0, 0, 0, 0ìœ¼ë¡œ í•´ì¤˜.\n"
                            f"- df ê¸°ì¤€ìœ¼ë¡œ ì—†ëŠ” ë‚´ìš©ì„ ì¶”ê°€í•˜ì§€ ë§ê²ƒ"
                            f"- JSON í˜•ì‹ì´ ì •í™•í•˜ë„ë¡ ë°˜í™˜í•  ê²ƒ!\n"
                            f"- JSON í˜•ì‹ ì´ì™¸ì˜ ì–´ë–¤ ì•Œë¦¼, ë‚´ìš©ì€ ì²¨ê°€í•˜ì§€ ë§ê²ƒ!\n"
                            f"- ë°˜í™˜ ë‚´ìš© ì™¸ì˜ ê²½ê³ , ì•Œë¦¼ì€ ë°˜í™˜í•˜ì§€ ë§ê²ƒ\n"
                            f" 'ì•„ë˜ëŠ” ì œê³µëœ `xy` ë° `df` ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° í•­ëª©ì„ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤'ì™€ ê°™ì€ ì•Œë¦¼ì€ ì ˆëŒ€ ê¸ˆì§€\n"
                            f" OpenAI ì‘ë‹µë‚´ìš©ê¸ˆì§€\n"

                        )
                    }
                    ]
                }
            ],
            max_tokens=5000,
            temperature=0.2,
            top_p=1.0
        )
        
        text = response.choices[0].message.content
        try:
            # format_registry_json í•¨ìˆ˜ ì‚¬ìš©
            output_file = f"ocr_result_page_{page_number}.json"
            formatted_result = format_registry_json(text, output_file)
            
            # JSON íŒŒì¼ ì½ê¸°
            with open(formatted_result, 'r', encoding='utf-8') as f:
                json_data = json.load(f)

            # í˜„ì¬ êµ¬ì¡° - scanned_documentsì— ì €ì¥
            save_ocr_result_to_firestore(
                group_id=group_id,
                document_type=doc_type,
                page_number=int(page_number),
                json_data=json_data
            )
            
            """
            # ëª©í‘œ êµ¬ì¡° - analyses ì»¬ë ‰ì…˜ì— ì €ì¥ (ì£¼ì„ ì²˜ë¦¬)
            save_ocr_result_to_firestore(
                user_id=user_id,
                contract_id=contract_id,
                document_type=doc_type,
                page_number=int(page_number),
                json_data=json_data
            )
            """
            
            
            all_results[f"page{page_number}"] = json_data
            
        except json.JSONDecodeError as e:
            print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            continue

    return all_results if all_results else None
