import time
import pandas as pd
import cv2
import json
from PIL import Image
import requests
import uuid
import time
import openai
import re
import base64
import numpy as np
import os
from io import BytesIO
from dotenv import load_dotenv
from firebase_api.utils import save_ocr_result_to_firestore

load_dotenv()

# API ì„¤ì •
secret_key = os.getenv("OCR_SECRET_KEY")
api_url = os.getenv("OCR_API_URL")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MODEL = "gpt-4o" # ì¼ë‹¨ í´ë¡œë“œê°€ ë²„ì „ ë°”ê¾¸ë¼í•´ì„œ ë°”ê¾¸ëŠ”ë° ë‚˜ì¤‘ì— ë¬¸ì œìƒê¸°ë©´ 4-oë¡œ

client = openai.OpenAI(api_key=OPENAI_API_KEY)
#ê³„ì•½ì„œì›ë³¸ì–‘ì‹
def base_xy():
    rows = [
        ['ë“±ê¸°ì‚¬í•­ì „ë¶€ì¦ëª…ì„œ',348,112,934,162],
        ['ì§‘í•©ê±´ë¬¼',520,166,766,216],
        ['[ì§‘í•©ê±´ë¬¼] ê±´ë¬¼ì£¼ì†Œ',26,298,908,346],
        ['[í‘œì œë¶€](1ë™ì˜ ê±´ë¬¼ì˜ í‘œì‹œ)',94,354,632,392],
        ['í‘œì‹œë²ˆí˜¸',34,406,130,444],
        ['ì ‘ìˆ˜',172,414,268,440],
        ['ì†Œì¬ì§€ë²ˆ, ê±´ë¬¼ ëª…ì¹­ ë° ë²ˆí˜¸', 318,410,590,440],
        ['([ë„ë¡œëª…ì£¼ì†Œ])',312,456,580,642],
        ['ê±´ë¬¼ë‚´ì—­',668,410,808,446],
        ['ë“±ê¸° ì›ì¸ ë° ê¸°íƒ€ì‚¬í•­',904,404,1140,448],
        ['ì—´ëŒì¼ì‹œ',22,1620,456,1656],
        ['(ëŒ€ì§€ê¶Œì´ ëª©ì ì¸ í† ì§€ì˜ í‘œì‹œ)',408,2456,788,2496],
        ['[í‘œì œë¶€] (ì „ìœ ë¶€ë¶„ì˜ ê±´ë¬¼ì˜ í‘œì‹œ)',80,2672,684,2720],
        ['í‘œì‹œë²ˆí˜¸',40,2740,130,2776],
        ['ì ‘ìˆ˜',166,2732,280,2776],
        ['ê±´ë¬¼ë²ˆí˜¸',322,2732,480,2780],
        ['(ê±´ë¬¼ë²ˆí˜¸)',316,2784,490,2842],
        ['ê±´ë¬¼ë‚´ì—­',522,2742,694,2770],
        ['(ê±´ë¬¼ë‚´ì—­)',506,2790,706,2850],
        ['ë“±ê¸°ì›ì¸ ë° ê¸°íƒ€ì‚¬í•­',806,2736,1064,2772],
        ['[ê°‘ êµ¬] (ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)',86,3842,654,3898],
        ['ìˆœìœ„ë²ˆí˜¸',46,3908,134,3948], 
        ['ë“±ê¸°ëª©ì ',170,3910,314,3944],
        ['ì ‘ìˆ˜', 390,3904,490,3946],
        ['ë“±ê¸°ì›ì¸',524,3906,668,3952],
        ['ê´€ë¦¬ì ë° ê¸°íƒ€ì‚¬í•­', 824,3902,1030,3946],
        ['ì†Œìœ ì', 824,3902,1030,4462],
        ['[ì„ êµ¬] (ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ëŒ€í•œ ì‚¬í•­)', 88,4562,796,4608],
        ['ìˆœìœ„ë²ˆí˜¸',46,4628,134,4658],
        ['ë“±ê¸°ëª©ì ',170,4628,314,4658],
        ['ì ‘ìˆ˜', 390,4628,490,4658],
        ['ë“±ê¸°ì›ì¸',524,4628,668,4658],
        ['ê´€ë¦¬ì ë° ê¸°íƒ€ì‚¬í•­',824,4628,1030,4658],
        ['(ì±„ê¶Œìµœê³ ì•¡)',718,4662,1156,4752],
        ['ì´í•˜ì—¬ë°±',410,4952,689,4990]
    ]
    xy = pd.DataFrame(columns=['Text', 'x1', 'y1', 'x2', 'y2'])
    xy = pd.concat([xy, pd.DataFrame(rows, columns=xy.columns)], ignore_index=True)
    return xy

def merge_images(image_urls):
    """Firebase URLë¡œë¶€í„° ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ë³‘í•©"""
    target_size = (1240, 1755)  # ì›í•˜ëŠ” ì´ë¯¸ì§€ í¬ê¸°

    # ì´ë¯¸ì§€ ë¶ˆëŸ¬ì™€ í¬ê¸° ì¡°ì •
    images = []
    for url in image_urls:
        # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        response = requests.get(url)
        if response.status_code == 200:
            # ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            image = Image.open(BytesIO(response.content))
            # PIL Imageë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            # í¬ê¸° ì¡°ì •
            resized_image = cv2.resize(opencv_image, target_size, interpolation=cv2.INTER_AREA)
            # ë‹¤ì‹œ PIL Imageë¡œ ë³€í™˜
            images.append(Image.fromarray(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)))
    
    # ì´ë¯¸ì§€ ë³‘í•©
    total_height = sum(img.height for img in images)
    max_width = max(img.width for img in images)
    merged_image = Image.new("RGB", (max_width, total_height))

    # ì´ë¯¸ì§€ ë¶™ì´ê¸°
    y_offset = 0
    for img in images:
        merged_image.paste(img, (0, y_offset))
        y_offset += img.height
    
    return merged_image

# def get_page_of_text(y_coordinate, page_count):
#     """
#     y ì¢Œí‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì–´ë–¤ í˜ì´ì§€ì— ìˆëŠ”ì§€ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜
    
#     :param y_coordinate: í…ìŠ¤íŠ¸ì˜ y ì¢Œí‘œ
#     :param page_count: ì „ì²´ í˜ì´ì§€ ìˆ˜
#     :return: í•´ë‹¹ í…ìŠ¤íŠ¸ê°€ ìˆëŠ” í˜ì´ì§€ ë²ˆí˜¸
#     """
#     page_height = 1755  # ê° í˜ì´ì§€ì˜ ë†’ì´
    
#     for page in range(1, page_count + 1):
#         if (page - 1) * page_height <= y_coordinate < page * page_height:
#             return page
    
#     return 1  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì²« í˜ì´ì§€ ë°˜í™˜

def get_page_height(url):
    """ì´ë¯¸ì§€ URLë¡œë¶€í„° ë†’ì´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    response = requests.get(url)
    if response.status_code == 200:
        image = Image.open(BytesIO(response.content))
        return image.height
    return 1755  # ê¸°ë³¸ ë†’ì´

## í•¨ìˆ˜ ì¶”ê°€ê°€
def organize_by_pages(data, page_heights):
    """í˜ì´ì§€ë³„ë¡œ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”í•˜ê³  ì¢Œí‘œë¥¼ ë³´ì •í•˜ëŠ” í•¨ìˆ˜"""
    
    # í˜ì´ì§€ ê²½ê³„ ê³„ì‚°
    page_boundaries = []
    current_height = 0
    for height in page_heights:
        page_boundaries.append({
            'start': current_height,
            'end': current_height + height
        })
        current_height += height

    # ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
    result = {f"{i+1}í˜ì´ì§€": {} for i in range(len(page_heights))}
    
    # ê° í•­ëª©ì„ í•´ë‹¹í•˜ëŠ” í˜ì´ì§€ì— í• ë‹¹
    for key, value in data.items():
        if isinstance(value, dict) and "bounding_box" in value:
            y1 = value["bounding_box"]["y1"]
            
            # y1 ê°’ì´ ì–´ëŠ í˜ì´ì§€ ë²”ìœ„ì— ì†í•˜ëŠ”ì§€ í™•ì¸
            for page_num, boundary in enumerate(page_boundaries):
                if boundary['start'] <= y1 < boundary['end']:
                    # í•´ë‹¹ í˜ì´ì§€ì— í•­ëª© ì¶”ê°€
                    page_key = f"{page_num+1}í˜ì´ì§€"
                    new_value = value.copy()
                    # y ì¢Œí‘œ ë³´ì •
                    new_value["bounding_box"]["y1"] -= boundary['start']
                    new_value["bounding_box"]["y2"] -= boundary['start']
                    result[page_key][key] = new_value
                    break
    
    return result

def cre_ocr(image):
    """PIL Image ê°ì²´ì— ëŒ€í•´ OCR ì‹¤í–‰"""
    request_json = {
        'images': [
            {
                'format': 'jpg',
                'name': 'demo'
            }
        ],
        'requestId': str(uuid.uuid4()),
        'version': 'V2',
        'timestamp': int(round(time.time() * 1000))
    }

    # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ ë²„í¼ë¡œ ë³€í™˜
    buffer = BytesIO()
    image.save(buffer, format="JPEG")
    image_bytes = buffer.getvalue()

    payload = {'message': json.dumps(request_json).encode('UTF-8')}
    files = [('file', ('image.jpg', image_bytes, 'image/jpeg'))]
    headers = {'X-OCR-SECRET': secret_key}

    response = requests.post(api_url, headers=headers, data=payload, files=files)

    if response.status_code == 200:
        ocr_results = response.json()

        all_data = []
        for image_result in ocr_results['images']:
            for field in image_result['fields']:
                text = field['inferText']
                bounding_box = field['boundingPoly']['vertices']
                x1, y1 = int(bounding_box[0]['x']), int(bounding_box[0]['y'])
                x2, y2 = int(bounding_box[2]['x']), int(bounding_box[2]['y'])
                all_data.append({
                    "Text": text,
                    "x1": x1, "y1": y1,
                    "x2": x2, "y2": y2
                })
        df = pd.DataFrame(all_data)
        return df
    return None

def fix_json_format(text: str) -> str:
    """JSON í˜•ì‹ ì˜¤ë¥˜ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì •í•˜ëŠ” í•¨ìˆ˜"""
    text = text.strip()
    text = text.replace("```json", "").replace("```", "").strip()
    
    json_end_index = text.rfind("}")
    if json_end_index != -1:
        text = text[:json_end_index+1]
    
    text = re.sub(r'}\s*{', '}, {', text)
    text = re.sub(r'(\d{1,3})(\d{3},\d{3})', r'\1,\2', text)
    
    return text

def format_registry_json(text: str, output_file: str) -> str:
    """OCR ê²°ê³¼ JSON ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ê³  ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    try:
        text = fix_json_format(text)
        data = json.loads(text)

        def fix_text(value):
            if value == "NA":
                return value
            value = re.sub(r'(\d+)\s+(\d+)', r'\1,\2', value)
            return value.strip()

        for key, value in data.items():
            if isinstance(value, dict) and "text" in value:
                value["text"] = fix_text(value["text"])

        y1_value = data.get("(ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)", {}).get("bounding_box", {}).get("y2", 0)
        y2_value = data.get("(ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ê´€í•œ ì‚¬í•­)", {}).get("bounding_box", {}).get("y1", 0)

        data["ê°‘êµ¬"] = {
            "text": "(ê°‘êµ¬)",
            "bounding_box": {
                "x1": 0,
                "y1": y1_value,
                "x2": 1200,
                "y2": y2_value
            }
        }

        # "(ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)"ê³¼ "(ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ê´€í•œ ì‚¬í•­)"ì„ ì‚­ì œ
        data.pop("(ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)", None)
        data.pop("(ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ê´€í•œ ì‚¬í•­)", None)

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=4)

        print(f"âœ… ë“±ê¸°ë¶€ë“±ë³¸ JSON ì •ë¦¬ ì™„ë£Œ: {output_file}")
        return output_file

    except json.JSONDecodeError as e:
        print(f"âŒ JSON ë³€í™˜ ì‹¤íŒ¨: {e}")
        print("ğŸ“Œ ì˜¤ë¥˜ ë°œìƒ JSON ë‚´ìš©:\n", text)
        return f"âŒ JSON ë³€í™˜ ì‹¤íŒ¨: {e}"

def registry_keyword_ocr(image_urls, doc_type, user_id, contract_id):
    """ë©”ì¸ OCR ì²˜ë¦¬ í•¨ìˆ˜"""

    page_numbers = [int(re.search(r'page(\d+)', url).group(1)) for url in image_urls]
    page_heights = []


    
    all_dfs = []
    y = 0
    
    # ê° í˜ì´ì§€ë³„ OCR ìˆ˜í–‰ ë° ë†’ì´ ì •ë³´ ìˆ˜ì§‘
    for url in image_urls:
        response = requests.get(url)
        if response.status_code == 200:
            image = Image.open(BytesIO(response.content))
            page_heights.append(image.height)
            
            # ê° í˜ì´ì§€ë³„ OCR ìˆ˜í–‰
            df = cre_ocr(image)
            if df is not None:
                df["y1"] += y
                df["y2"] += y
                all_dfs.append(df)
                y += image.height
    
    merged_df = pd.concat(all_dfs, ignore_index=True)

    xy = base_xy()
    xy_json = xy.to_json(orient="records", force_ascii=False)
    df_json = merged_df.to_json(orient="records", force_ascii=False)

    # current_page = re.search(r'page(\d+)', image_urls[0]).group(1)
    # page_number = int(current_page)  # strì„ intë¡œ ë³€í™˜
    # page_count = len(image_urls)  # ì „ì²´ í˜ì´ì§€ ìˆ˜

    target_texts = {
            "ì¢…ë¥˜": "ë“±ë³¸ ì¢…ë¥˜ (ì§‘í•©ê±´ë¬¼, ê±´ë¬¼, í† ì§€ ì¤‘ í•˜ë‚˜)",
            "(ê±´ë¬¼ì£¼ì†Œ)": "[ë“±ë³¸ì¢…ë¥˜] ë„ë¡œëª… ì£¼ì†Œ (ì˜ˆ: [ì§‘í•©ê±´ë¬¼] ì •ì™•ëŒ€ë¡œ 53ë²ˆê¸¸ 29)",
            "ì—´ëŒì¼ì‹œ": "yyyyë…„ mmì›” ddì¼ hhì‹œmmë¶„ssì´ˆ",
            "(ê°‘êµ¬)":"í…ìŠ¤íŠ¸",
            "(ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)": "(ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)",
            "ì†Œìœ ì":"ì´ë¦„",
            "ì‹ íƒ":"ì‹ íƒ (ì˜ˆ: ì‹ íƒ, ì´ì™¸ì˜ ë‹¤ë¥¸ ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ì•ˆë¨)",
            "ì••ë¥˜":"ì••ë¥˜ (ì˜ˆ: ì••ë¥˜, ì´ì™¸ì˜ ë‹¤ë¥¸ ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ì•ˆë¨)",
            "ê°€ì²˜ë¶„":"ê°€ì²˜ë¶„ (ì˜ˆ: ê°€ì²˜ë¶„, ì´ì™¸ì˜ ë‹¤ë¥¸ ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ì•ˆë¨)",
            "ê°€ì••ë¥˜":"ê°€ì••ë¥˜ (ì˜ˆ: ê°€ì••ë¥˜, ì´ì™¸ì˜ ë‹¤ë¥¸ ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ì•ˆë¨)",
            "(ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ëŒ€í•œ ì‚¬í•­)":"(ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ëŒ€í•œ ì‚¬í•­)",
            "(ì±„ê¶Œìµœê³ ì•¡)": "ìµœê³ ì±„ê¶Œì•¡ ê¸ˆ ###ì›(ì˜ˆ: ì±„ê¶Œìµœê³ ì•¡ ê¸ˆ1,000,000,000ì›)",
            "ì´í•˜ì—¬ë°±": "ì´ í•˜ ì—¬ ë°±"
        }
    
    
    # GPT ë¶„ì„ ìš”ì²­
    response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    "role": "system",
                    "content": "JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ë§ˆí¬ë‹¤ìš´ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": [
                        {
                        "type": "text",
                        "text": (
                           f"ë‹¤ìŒì€ OCR ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ì…ë‹ˆë‹¤.\n\n"
                            f"**ìœ„ì¹˜ ë°ì´í„° (xy):**\n{xy_json}\n\n"
                            f"**ë‚´ìš© ë°ì´í„° (df):**\n{df_json}\n\n"
                            f"**ì‘ì—… ëª©í‘œ:**\n"
                            f"- ë‚´ìš©ì´ ì—†ìœ¼ë©´ 'NA'ë¡œ í‘œì‹œ\n\n"
                            f"- `xy` ë°ì´í„°ì˜ ìœ„ì¹˜ ì •ë³´(ì¢Œí‘œ)ë¥¼ í™œìš©í•˜ì—¬ `df` ë°ì´í„°ì™€ ë§¤ì¹­. {xy_json}ì˜ ìœ„ì¹˜ëŠ” ì°¸ê³ ë§Œí•˜ê³  í•­ìƒ {df_json}ì„ ë”°ë¥¸ë‹¤.\n"
                            f"- 'xy' ë°ì´í„°ì˜ ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸°ëŠ” 'df'ì— ë§ê²Œ ì¡°ì •ëœë‹¤"
                            f" **ê° í•­ëª©ì˜ ì¶œë ¥ í˜•ì‹:**\n"
                            + "\n".join([f"- **{key}**: {value}" for key, value in target_texts.items()]) +
                            f"\n\n**ê²°ê³¼ í˜•ì‹:**\n"
                            f"- JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ (ê° í•­ëª©ì˜ ë°”ìš´ë”© ë°•ìŠ¤ í¬í•¨)\n"
                            f"- **ì¶œë ¥ ë°ì´í„°ê°€ ì§€ì •ëœ í˜•ì‹ê³¼ ë‹¤ë¥¼ ê²½ìš° ìë™ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜**\n\n"
                            f"**ë°˜í™˜ ì˜ˆì‹œ:**\n"
                            f"{{\n"
                            f"  \"ì¢…ë¥˜\": {{\"text\": \"ì§‘í•©ê±´ë¬¼\", \"bounding_box\": {{\"x1\": 100, \"y1\": 200, \"x2\": 300, \"y2\": 250}}}},\n"
                            f"  \"ê±´ë¬¼ì£¼ì†Œ\": {{\"text\": \"ì •ì™•ëŒ€ë¡œ 53ë²ˆê¸¸ 29\", \"bounding_box\": {{\"x1\": 120, \"y1\": 220, \"x2\": 320, \"y2\": 270}}}},\n"
                            f"  \"(ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)\": {{\"text\": \"( ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­ )\", \"bounding_box\": {{\"x1\": 120, \"y1\": 220, \"x2\": 320, \"y2\": 270}}}},\n"
                            f"  \"ì†Œìœ ì£¼\": {{\"text\": \"( ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­ )\", \"bounding_box\": {{\"x1\": 120, \"y1\": 220, \"x2\": 320, \"y2\": 270}}}},\n"
                            f"  \"(ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ê´€í•œ ì‚¬í•­)\": {{\"text\": \"(ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ê´€í•œ ì‚¬í•­)\", \"bounding_box\": {{\"x1\": 120, \"y1\": 220, \"x2\": 320, \"y2\": 270}}}},\n"                            
                            f"  \"ì—´ëŒì¼ì‹œ\": {{\"text\": \"2025ë…„ 02ì›” 15ì¼ 14ì‹œ 48ë¶„\", \"bounding_box\": {{\"x1\": 150, \"y1\": 250, \"x2\": 350, \"y2\": 300}}}},\n"
                            f"  \"ì±„ê¶Œìµœê³ ì•¡\": {{\"text\": \"ì±„ê¶Œìµœê³ ì•¡ ê¸ˆ1,000,000,000ì›\", \"bounding_box\": {{\"x1\": 170, \"y1\": 270, \"x2\": 370, \"y2\": 320}}}}\n"
                            f"}}\n\n"
                            f"**ì£¼ì˜ì‚¬í•­:**\n"
                            f"- ëª¨ë“  ì¢Œí‘œëŠ” dfë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¶œë ¥í•œë‹¤."
                            f"- dfë¥¼ í•­ìƒ ìš°ì„ ì‹œí•œë‹¤."
                            f"- íŠ¹ì•½ì‚¬í•­ì€ í•´ë‹¹ í˜ì´ì§€ì˜ ë§ˆì§€ë§‰ í…ìŠ¤íŠ¸ê¹Œì§€ í¬í•¨í•œë‹¤."
                            f"- í…ìŠ¤íŠ¸ê°€ ì—¬ëŸ¬ ë°”ìš´ë”© ë°•ìŠ¤ì— ê±¸ì³ ìˆëŠ” ê²½ìš°, ì¤‘ì‹¬ì  ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨\n"
                            f"- ë‚´ìš©ì´ ì—†ì„ ê²½ìš° `NA`ë¡œ ë°˜í™˜, text ë‚´ìš©ì´ ì—†ëŠ” ê²½ìš° ì¢Œí‘œë¥¼ 0, 0, 0, 0ìœ¼ë¡œ í•´ì¤˜.\n"
                            f"- df ê¸°ì¤€ìœ¼ë¡œ ì—†ëŠ” ë‚´ìš©ì„ ì¶”ê°€í•˜ì§€ ë§ê²ƒ"
                            f"- ì†Œìœ ì£¼ëŠ” '(ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ê´€í•œ ì‚¬í•­)'ì™€ '(ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­) ì‚¬ì´ì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  ì´ë¦„ì´ë‹¤'"
                            f"- ì†Œìœ ì£¼ê°€ ì—¬ëŸ¬ëª…ì¸ ê²½ìš° ì†Œìœ ì£¼_1, ì†Œìœ ì£¼_2 ì˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ëœë‹¤"
                            f"- ì±„ê¶Œìµœê³ ì•¡ì€ '(ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)' ê³¼ 'ì´í•˜ì—¬ë°±' ì‚¬ì´ì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  ê¸ˆì•¡ì´ë‹¤."
                            f"- ì±„ê¶Œìµœê³ ì•¡ì€ ì—¬ëŸ¬ê°œì¸ ê²½ìš° ì±„ê¶Œìµœê³ ì•¡_1, ì±„ê¶Œìµœê³ ì•¡_2ì˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ëœë‹¤."
                            f"- ì±„ê¶Œìµœê³ ì•¡ì€ ì±„ê¶Œìµœê³ ì•¡_i ì¤‘ ê°€ì¥ iê°€ í° ê²ƒë§Œì„ ì¶œë ¥í•œë‹¤."
                            f"- JSON í˜•ì‹ì´ ì •í™•í•˜ë„ë¡ ë°˜í™˜í•  ê²ƒ!\n"
                            f"- JSON í˜•ì‹ ì´ì™¸ì˜ ì–´ë–¤ ì•Œë¦¼, ë‚´ìš©ì€ ì²¨ê°€í•˜ì§€ ë§ê²ƒ!\n"
                            f"- ë°˜í™˜ ë‚´ìš© ì™¸ì˜ ê²½ê³ , ì•Œë¦¼ì€ ë°˜í™˜í•˜ì§€ ë§ê²ƒ\n"
                            f" 'ì•„ë˜ëŠ” ì œê³µëœ `xy` ë° `df` ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° í•­ëª©ì„ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤'ì™€ ê°™ì€ ì•Œë¦¼ì€ ì ˆëŒ€ ê¸ˆì§€\n"
                            f" OpenAI ì‘ë‹µë‚´ìš©ê¸ˆì§€\n"


                        )
                    }
                    ]
                }
            ],
            max_tokens=5000,
            temperature=0.2,
            top_p=1.0
        )
        
    text = response.choices[0].message.content.strip()
    data = json.loads(fix_json_format(text))

    # ë¶ˆí•„ìš”í•œ í•„ë“œ ì œê±°
    data.pop("(ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)", None)
    data.pop("(ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ëŒ€í•œ ì‚¬í•­)", None)

    # 6. í˜ì´ì§€ë³„ ë°ì´í„° êµ¬ì¡°í™”
    organized_data = organize_by_pages(data, page_heights)


    # 7. í˜ì´ì§€ ë²ˆí˜¸ í˜•ì‹ ë§ì¶”ê¸°
    page_structured_data = {}
    for i, (old_key, value) in enumerate(organized_data.items()):
        new_key = f"page{page_numbers[i]}"
        page_structured_data[new_key] = value

    return page_structured_data

    

    # page_structured_data = {}
    
    # for key, value in data.items():
    #     if isinstance(value, dict) and "bounding_box" in value:
    #         # ì›ë³¸ í˜ì´ì§€ ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ í˜ì´ì§€ ê²°ì •
    #         page_index = get_page_of_text(value["bounding_box"]["y1"], page_count)
    #         page_key = f"page{page_numbers[page_index - 1]}"
            
    #         # í˜ì´ì§€ë³„ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
    #         if page_key not in page_structured_data:
    #             page_structured_data[page_key] = {}
            
    #         # í•´ë‹¹ í˜ì´ì§€ì— ë°ì´í„° ì¶”ê°€
    #         page_structured_data[page_key][key] = value

    # ê¸°ì¡´ì˜ ê°‘êµ¬ ë° ë¶ˆí•„ìš”í•œ í•„ë“œ ì²˜ë¦¬ ë¡œì§
    # y1_value = data.get("(ì†Œìœ ê¶Œì— ê´€í•œ ì‚¬í•­)", {}).get("bounding_box", {}).get("y2", "ê°’ ì—†ìŒ")
    # y2_value = data.get("(ì†Œìœ ê¶Œ ì´ì™¸ì˜ ê¶Œë¦¬ì— ê´€í•œ ì‚¬í•­)", {}).get("bounding_box", {}).get("y1", "ê°’ ì—†ìŒ")

    # if isinstance(y1_value, (int, float)) and isinstance(y2_value, (int, float)):
    #     # ê°‘êµ¬ì˜ í˜ì´ì§€ ê²°ì •
    #     ê°‘êµ¬_page_index = get_page_of_text(y1_value, page_count)
    #     page_key = f"page{page_numbers[ê°‘êµ¬_page_index - 1]}"
    #     page_structured_data[page_key]["ê°‘êµ¬"] = {
    #         "text": "(ê°‘êµ¬)",
    #         "bounding_box": {
    #             "x1": 0,
    #             "y1": y1_value,
    #             "x2": 1200,
    #             "y2": y2_value
    #         }
    #     }
